{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read namuwiki dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/namuwiki.json') as f:\n",
    "    context_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = defaultdict(dict)\n",
    "for doc in context_:\n",
    "    context[doc['title']][doc['namespace']] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namuwiki document parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_documnet = re.compile('\\[\\[(.[^:]+?)\\]\\]')\n",
    "regex_attach = re.compile('\\[\\[파일:(.+?)\\]\\]')\n",
    "regex_comment = re.compile('\\[\\*(.+?)\\]')\n",
    "regex_table = re.compile('\\|\\|(.+?)\\|\\|(.+?)\\|\\|')\n",
    "regex_link = re.compile('\\[\\[(.[^:\\[\\]]+?)\\|(.[^:\\[\\]]+?)\\]\\]')\n",
    "regex_del = re.compile('~~(.+?)~~')\n",
    "regex_tag = re.compile('\\<(.+?)\\>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get drama titles from channles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = [\"JTBC 금토 드라마(2014~2017)\", \"JTBC 금토 드라마(2017~2020)\", \"JTBC 드라마\", \"JTBC 수목 드라마\", \"JTBC 월화 드라마(2011~2014)\", \"JTBC 월화 드라마(2017~2020)\", \"JTBC 주말 드라마\", \"KBS 수목 드라마(2001~2005)\", \"KBS 수목 드라마(2006~2010)\", \"KBS 수목 드라마(2011~2015)\", \"KBS 수목 드라마(2016~2020)\", \"KBS 월화 드라마(2001~2005)\", \"KBS 월화 드라마(2006~2010)\", \"KBS 월화 드라마(2011~2015)\", \"KBS 월화 드라마(2016~2020)\", \"KBS 학교 시리즈\", \"MBC 수목 미니시리즈(2006~2010)\", \"MBC 수목 미니시리즈(2011~2015)\", \"MBC 수목 미니시리즈(2016~2020)\", \"MBC 아침 드라마(2011~2015)\", \"MBC 아침 드라마(2016~2020)\", \"MBC 예능 드라마\", \"MBC 월화 미니시리즈(2006~2010)\", \"MBC 월화 미니시리즈(2016~2020)\", \"MBC 월화특별기획(2011~2015)\", \"MBC 일일 드라마(2016~2020)\", \"MBC 일일 연속극(2011~2015)\", \"MBC 주말 드라마(2011~2015)\", \"MBC 주말 드라마(2016~2020)\", \"MBC 주말 특별기획(2011~2015)\", \"MBC 주말 특별기획(2016~2020)\", \"MBC 하이킥 시리즈\", \"MBN 수목 드라마\", \"OCN 로맨스 드라마\", \"OCN 수목 오리지널\", \"OCN 오리지널 드라마(2010~2016)\", \"OCN 월화 오리지널\", \"OCN 토일 오리지널(2017~2020)\", \"SBS 금토 드라마(2019~현재)\", \"SBS 드라마 스페셜(1992~1995)\", \"SBS 드라마 스페셜(1996~2000)\", \"SBS 드라마 스페셜(2001~2005)\", \"SBS 드라마 스페셜(2006~2010)\", \"SBS 드라마 스페셜(2011~2015)\", \"SBS 드라마 스페셜(2016~2020)\", \"SBS 아침 연속극(2016~2020)\", \"SBS 월화 드라마(1991~1995)\", \"SBS 월화 드라마(1996~2000)\", \"SBS 월화 드라마(2001~2005)\", \"SBS 월화 드라마(2006~2010)\", \"SBS 월화 드라마(2011~2015)\", \"SBS 월화 드라마(2016~2020)\", \"TV CHOSUN 토일드라마\", \"tvN 금요 드라마(2007~2015)\", \"tvN 금토 드라마\", \"tvN 로맨스가 필요해 시리즈\", \"tvN 불금 시리즈(2017~)\", \"tvN 월화 드라마(2011~2015)\", \"tvN 월화 드라마(2016~2020)\", \"tvN 토일 드라마(2017~2020)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interested:\n",
    "    document = context[inter]\n",
    "    matches = regex_documnet.findall(document['1']['text'])\n",
    "    \n",
    "    for match in matches:\n",
    "        name, *_ = match.split('|')\n",
    "        name, *_ = name.split('#')\n",
    "        titles.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    '방송 기간': ['방송기간', '방송 기간'],\n",
    "    '방송 횟수': ['횟수', '방송 횟수'],\n",
    "    '장르': ['장르'],\n",
    "    '채널': ['채널', '방송사'],\n",
    "    '제작사': ['제작사', '제작자', '제작'],\n",
    "    '극본': ['극본', '대본'],\n",
    "    '출연자': ['출연자', '출연', '출연진'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notexists = []\n",
    "notparser = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        document = context[title]['0']['text']                       \n",
    "    except KeyError:\n",
    "        notexists.append(title)\n",
    "        \n",
    "    matches = regex_table.findall(document)\n",
    "    \n",
    "    d = {key: '' for key in columns}\n",
    "    \n",
    "    for key, value in matches:\n",
    "        key = next((ckey for ckey, cvalues in columns.items() if any(cvalue in key for cvalue in cvalues)), False)\n",
    "        if key:\n",
    "            d[key] = value\n",
    "    \n",
    "    if not d:\n",
    "        notparser.append(title)\n",
    "    else:\n",
    "        data[title] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = list(columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.empty((0, len(table_columns) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, values in data.items():\n",
    "    d = [regex_tag.sub('', regex_comment.sub('', regex_del.sub(r'\\1', regex_documnet.sub(r'\\1', regex_link.sub(r'\\1', regex_attach.sub('attach', values[column])))))).strip() \n",
    "         for column in table_columns]\n",
    "    table = np.vstack((table, np.array([title, *d])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.columns = ['title', *table_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../results/namuwiki.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
