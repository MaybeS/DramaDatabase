{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read namuwiki dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/namuwiki.json') as f:\n",
    "    context_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = defaultdict(dict)\n",
    "for doc in context_:\n",
    "    context[doc['title']][doc['namespace']] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_document = re.compile('\\[\\[(.[^:]+?)\\]\\]')\n",
    "regex_table = re.compile('(?<=\\|\\|)(.*)(?=\\|\\|)')\n",
    "regex_bracket = re.compile('\\((.+?)\\)')\n",
    "regex_redirect = re.compile('#redirect (.+?)')\n",
    "\n",
    "regex_tags = OrderedDict({\n",
    "    'horizontal_line': ('', re.compile('\\-{4,9}')),\n",
    "    'comment': ('', re.compile('##\\s?(.*)')),\n",
    "    \n",
    "    'header': (r'\\1', re.compile('\\={2,6}\\#?(.+?)\\#?\\={2,6}')),\n",
    "    'bold': (r'\\1', re.compile(\"\\'\\'\\'(.+?)\\'\\'\\'\")),\n",
    "    'italic': (r'\\1', re.compile(\"\\'\\'(.+?)\\'\\'\")),\n",
    "    'strike1': (r'\\1', re.compile('~~(.+?)~~')),\n",
    "    'strike2': (r'\\1', re.compile('--(.+?)--')),\n",
    "    'underline': (r'\\1', re.compile('__(.+?)__')),\n",
    "    'upper': (r'\\1', re.compile('\\^\\^(.+?)\\^\\^')),\n",
    "    'under': (r'\\1', re.compile(',,(.+?),,')),\n",
    "    \n",
    "    'bigger': (r'\\1', re.compile('\\{\\{\\{\\+[1-5] (.+?)\\}\\}\\}')),\n",
    "    'smaller': (r'\\1', re.compile('\\{\\{\\{\\-[1-5] (.+?)\\}\\}\\}')),\n",
    "    'color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}')),\n",
    "    'without_markup': (r'\\1', re.compile('\\{\\{\\{(.*)\\}\\}\\}')),\n",
    "    \n",
    "    'macro_html': (r'\\1', re.compile('\\{\\{\\{\\#\\!html (.+?)\\}\\}\\}')),\n",
    "    'macro_wiki': (r'\\2', re.compile('\\{\\{\\{\\#\\!wiki (.+?)\\n(.*)\\}\\}\\}')),\n",
    "    'macro_syntax': (r'\\2', re.compile('\\{\\{\\{\\#\\!syntax (.+?)\\n(.*)\\n\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_math': ('', re.compile('\\[math\\((.+?)\\)\\]', re.IGNORECASE)),\n",
    "    'macro_date': ('', re.compile('\\[date(time)?\\]', re.IGNORECASE)),\n",
    "    'macro_br': ('\\n', re.compile('\\[br\\]', re.IGNORECASE)),\n",
    "    'macro_include': ('', re.compile('\\[include(.+?)\\]', re.IGNORECASE)),\n",
    "    'macro_index': ('', re.compile('\\[목차\\]')),\n",
    "    'macro_index_': ('', re.compile('\\[tableofcontents\\]')),\n",
    "    'macro_footnote': ('', re.compile('\\[각주\\]')),\n",
    "    'macro_footnote_': ('', re.compile('\\[footnote\\]')),\n",
    "    'macro_pagecount': ('', re.compile('\\[pagecount(.+?)?\\]', re.IGNORECASE)),\n",
    "    'macro_age': ('', re.compile('\\[age\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_dday': ('', re.compile('\\[dday\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_tag': ('', re.compile('\\<(.+?)\\>')),\n",
    "\n",
    "    'attach_': (r'\\1', re.compile('\\[\\[파일:(.+?)\\|(.+?)\\]\\]')),\n",
    "    'attach': (r'\\1', re.compile('\\[\\[파일:(.+?)\\]\\]')),\n",
    "    \n",
    "    'paragraph_': (r'\\1', re.compile('\\[\\[#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'paragraph': (r'\\1', re.compile('\\[\\[#s-(.+?)\\]]')),\n",
    "    'link_paragraph_': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'link_paragraph': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\]\\]')),\n",
    "    'link': (r'\\1', re.compile('\\[\\[((?:(?!\\|).)+?)\\]\\]')),\n",
    "    'link_': (r'\\1', re.compile('\\[\\[(.+?)\\|(.+?)\\]\\]')),\n",
    "    \n",
    "    'list': (r'\\1', re.compile('\\|\\*\\|(.*)')),\n",
    "    'list_': (r'\\1', re.compile('\\|\\*(.*)')),\n",
    "    'list__': (r'\\1', re.compile('\\|[1Aa]\\.\\|(.*)')),\n",
    "    'list___': (r'\\1', re.compile('\\|[1Aa]\\.(.*)')),\n",
    "    'unordred_list': (r'\\1', re.compile('[ ]+\\*(.*)')),\n",
    "    'ordered_list': (r'\\1', re.compile('[ ]+[1AaIi]\\.(.*)')),\n",
    "    'quote': (r'\\1', re.compile('\\>+\\s?(.*)')),\n",
    "\n",
    "    'footnote': ('', re.compile('\\[\\*[A-Za-z]? (.+?)\\]')),    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str, verbose: bool = False) -> str:\n",
    "    def _parse(text: str, target: str, tag: re.Pattern) \\\n",
    "        -> Tuple[str, int]:\n",
    "        return tag.subn(target, text)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Parsing Regex {len(regex_tags.keys())} rules\\n\\t{text}')\n",
    "    \n",
    "    while True:\n",
    "        count = 0\n",
    "        for key, (target, tag) in regex_tags.items():\n",
    "            text, count = _parse(text, target, tag)\n",
    "            if count:\n",
    "                if verbose:\n",
    "                    print(f'Rule [{key}: {tag}]\\n\\t{text}')\n",
    "                break\n",
    "        if not count:\n",
    "            break\n",
    "            \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(text):\n",
    "    for row in regex_table.findall(text):\n",
    "        values = row.split('||')\n",
    "        yield values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get drama titles from channles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = [\"JTBC 금토 드라마(2014~2017)\", \"JTBC 금토 드라마(2017~2020)\", \"JTBC 드라마\", \"JTBC 수목 드라마\", \"JTBC 월화 드라마(2011~2014)\", \"JTBC 월화 드라마(2017~2020)\", \"JTBC 주말 드라마\", \"KBS 수목 드라마(2001~2005)\", \"KBS 수목 드라마(2006~2010)\", \"KBS 수목 드라마(2011~2015)\", \"KBS 수목 드라마(2016~2020)\", \"KBS 월화 드라마(2001~2005)\", \"KBS 월화 드라마(2006~2010)\", \"KBS 월화 드라마(2011~2015)\", \"KBS 월화 드라마(2016~2020)\", \"KBS 학교 시리즈\", \"MBC 수목 미니시리즈(2006~2010)\", \"MBC 수목 미니시리즈(2011~2015)\", \"MBC 수목 미니시리즈(2016~2020)\", \"MBC 아침 드라마(2011~2015)\", \"MBC 아침 드라마(2016~2020)\", \"MBC 예능 드라마\", \"MBC 월화 미니시리즈(2006~2010)\", \"MBC 월화 미니시리즈(2016~2020)\", \"MBC 월화특별기획(2011~2015)\", \"MBC 일일 드라마(2016~2020)\", \"MBC 일일 연속극(2011~2015)\", \"MBC 주말 드라마(2011~2015)\", \"MBC 주말 드라마(2016~2020)\", \"MBC 주말 특별기획(2011~2015)\", \"MBC 주말 특별기획(2016~2020)\", \"MBC 하이킥 시리즈\", \"MBN 수목 드라마\", \"OCN 로맨스 드라마\", \"OCN 수목 오리지널\", \"OCN 오리지널 드라마(2010~2016)\", \"OCN 월화 오리지널\", \"OCN 토일 오리지널(2017~2020)\", \"SBS 금토 드라마(2019~현재)\", \"SBS 드라마 스페셜(1992~1995)\", \"SBS 드라마 스페셜(1996~2000)\", \"SBS 드라마 스페셜(2001~2005)\", \"SBS 드라마 스페셜(2006~2010)\", \"SBS 드라마 스페셜(2011~2015)\", \"SBS 드라마 스페셜(2016~2020)\", \"SBS 아침 연속극(2016~2020)\", \"SBS 월화 드라마(1991~1995)\", \"SBS 월화 드라마(1996~2000)\", \"SBS 월화 드라마(2001~2005)\", \"SBS 월화 드라마(2006~2010)\", \"SBS 월화 드라마(2011~2015)\", \"SBS 월화 드라마(2016~2020)\", \"TV CHOSUN 토일드라마\", \"tvN 금요 드라마(2007~2015)\", \"tvN 금토 드라마\", \"tvN 로맨스가 필요해 시리즈\", \"tvN 불금 시리즈(2017~)\", \"tvN 월화 드라마(2011~2015)\", \"tvN 월화 드라마(2016~2020)\", \"tvN 토일 드라마(2017~2020)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interested:\n",
    "    document = context[inter]\n",
    "    matches = regex_document.findall(document['1']['text'])\n",
    "    \n",
    "    for match in matches:\n",
    "        name, *_ = match.split('|')\n",
    "        name, *_ = name.split('#')\n",
    "        titles.add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    '방송 기간': ['방송기간', '방송 기간',' 방송 기간 '],\n",
    "    '방송 시간': ['방송 시간', '방송시간',' 방송시간 '],\n",
    "    '방송 횟수': ['횟수', '방송 횟수'],\n",
    "    '장르': ['장르'],\n",
    "    '채널': ['채널', '방송사'],\n",
    "#    '제작사': ['제작사', '제작자', '제작'],\n",
    "#    '극본': ['극본', '대본'],\n",
    "#    '출연자': ['출연자', '출연', '출연진'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)\n",
    "notexists = []\n",
    "notparser = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        if '(드라마)' not in title and f'{title}(드라마)' in context:\n",
    "            document = context[title]['0']['text']\n",
    "        else:\n",
    "            document = context[title]['0']['text']\n",
    "    except KeyError:\n",
    "        notexists.append(title)\n",
    "    d = defaultdict(str)\n",
    "    for row in parse_table(parse(document)):\n",
    "#         if title == '최고의 사랑' :\n",
    "#             print(row)\n",
    "        try:\n",
    "            key, value = filter(len, row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        key = next((ckey for ckey, cvalues in columns.items() if any(cvalue in key for cvalue in cvalues)), False)\n",
    "        if key:\n",
    "            key = key.strip()\n",
    "            d[key] = f'{d[key]} {value}'\n",
    "    \n",
    "    if not d:\n",
    "        notparser.append(title)\n",
    "    else:\n",
    "        data[title] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 pages are not parsable\n",
      "2 pages are not exists\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(notparser)} pages are not parsable')\n",
    "print(f'{len(notexists)} pages are not exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = list(columns.keys())\n",
    "table = np.empty((0, len(table_columns) + 1))\n",
    "\n",
    "for title, values in data.items():\n",
    "    table = np.vstack((table, np.array([\n",
    "        regex_bracket.sub('', title).replace(' ', '').strip(), *tuple(map(lambda c: values[c], table_columns))\n",
    "    ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.columns = ['제목', *table_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_date = re.compile('(.+?)년(.*)월(.*)일')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = []\n",
    "for index, date in enumerate(df['방송 기간']):\n",
    "    ds, *de = map(regex_date.findall, map(str.strip, date.split('~' if '~' in date else '-')))\n",
    "    ds, *_ = ds or ['unknown']\n",
    "    try:\n",
    "        date_start.append(pd.datetime(*tuple(map(int, ds))))\n",
    "    except (ValueError, TypeError):\n",
    "        date_start.append('unknown')\n",
    "    \n",
    "assert len(date_start) == np.size(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['방송 시작'] = pd.Series(date_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>방송 기간</th>\n",
       "      <th>방송 시간</th>\n",
       "      <th>방송 횟수</th>\n",
       "      <th>장르</th>\n",
       "      <th>채널</th>\n",
       "      <th>방송 시작</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그남자오수</td>\n",
       "      <td>2018년 3월 5일 ~ 2018년 4월 24일</td>\n",
       "      <td>월, 화 21:00~22:00</td>\n",
       "      <td>16부작</td>\n",
       "      <td>로맨스 범죄</td>\n",
       "      <td>OCN</td>\n",
       "      <td>2018-03-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>간택-여인들의전쟁</td>\n",
       "      <td>2019년 12월 14일 ~ 2020년 2월 9일</td>\n",
       "      <td>토요일, 일요일 오후 10:50 ~</td>\n",
       "      <td>16부작</td>\n",
       "      <td>로맨스, 퓨전사극</td>\n",
       "      <td>TV CHOSUN</td>\n",
       "      <td>2019-12-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>우리가만난기적</td>\n",
       "      <td>2018년 4월 2일 ~ 2018년 5월 29일</td>\n",
       "      <td>월요일, 화요일 오후 10:00 ~ 11:10</td>\n",
       "      <td>18부작</td>\n",
       "      <td></td>\n",
       "      <td>KBS 2TV</td>\n",
       "      <td>2018-04-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>왕과나</td>\n",
       "      <td>2007년 8월 27일 ~ 2008년 4월 1일</td>\n",
       "      <td>월요일, 화요일 밤 9:55 ~ 11:05</td>\n",
       "      <td>63부작</td>\n",
       "      <td></td>\n",
       "      <td>SBS</td>\n",
       "      <td>2007-08-27 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>굿캐스팅</td>\n",
       "      <td>2020년 4월 ~ (예정)</td>\n",
       "      <td>월요일, 화요일 오후 10:00 ~ 11:10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SBS</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          제목                          방송 기간                         방송 시간  \\\n",
       "0      그남자오수    2018년 3월 5일 ~ 2018년 4월 24일              월, 화 21:00~22:00    \n",
       "1  간택-여인들의전쟁   2019년 12월 14일 ~ 2020년 2월 9일           토요일, 일요일 오후 10:50 ~    \n",
       "2    우리가만난기적    2018년 4월 2일 ~ 2018년 5월 29일     월요일, 화요일 오후 10:00 ~ 11:10    \n",
       "3        왕과나    2007년 8월 27일 ~ 2008년 4월 1일       월요일, 화요일 밤 9:55 ~ 11:05    \n",
       "4       굿캐스팅               2020년 4월 ~ (예정)     월요일, 화요일 오후 10:00 ~ 11:10    \n",
       "\n",
       "     방송 횟수            장르            채널                방송 시작  \n",
       "0    16부작        로맨스 범죄           OCN   2018-03-05 00:00:00  \n",
       "1    16부작     로맨스, 퓨전사극     TV CHOSUN   2019-12-14 00:00:00  \n",
       "2    18부작                     KBS 2TV   2018-04-02 00:00:00  \n",
       "3    63부작                         SBS   2007-08-27 00:00:00  \n",
       "4                                 SBS               unknown  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../results/namuwiki.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
