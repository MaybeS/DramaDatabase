{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read namuwiki dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/namuwiki.json') as f:\n",
    "    context_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = defaultdict(dict)\n",
    "for doc in context_:\n",
    "    context[doc['title']][doc['namespace']] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_document = re.compile('\\[\\[(.[^:]+?)\\]\\]')\n",
    "regex_table = re.compile('(?<=\\|\\|)(.*)(?=\\|\\|)')\n",
    "regex_bracket = re.compile('\\((.+?)\\)')\n",
    "regex_redirect = re.compile('#redirect (.+?)')\n",
    "\n",
    "regex_tags = OrderedDict({\n",
    "    'horizontal_line': ('', re.compile('\\-{4,9}')),\n",
    "    'comment': ('', re.compile('##\\s?(.*)')),\n",
    "    \n",
    "    'header': (r'\\1', re.compile('\\={2,6}\\#?(.+?)\\#?\\={2,6}')),\n",
    "    'bold': (r'\\1', re.compile(\"\\'\\'\\'(.+?)\\'\\'\\'\")),\n",
    "    'italic': (r'\\1', re.compile(\"\\'\\'(.+?)\\'\\'\")),\n",
    "    'strike1': (r'\\1', re.compile('~~(.+?)~~')),\n",
    "    'strike2': (r'\\1', re.compile('--(.+?)--')),\n",
    "    'underline': (r'\\1', re.compile('__(.+?)__')),\n",
    "    'upper': (r'\\1', re.compile('\\^\\^(.+?)\\^\\^')),\n",
    "    'under': (r'\\1', re.compile(',,(.+?),,')),\n",
    "    \n",
    "    'bigger': (r'\\1', re.compile('\\{\\{\\{\\+[1-5] (.+?)\\}\\}\\}')),\n",
    "    'smaller': (r'\\1', re.compile('\\{\\{\\{\\-[1-5] (.+?)\\}\\}\\}')),\n",
    "    'color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}')),\n",
    "    'without_markup': (r'\\1', re.compile('\\{\\{\\{(.*)\\}\\}\\}')),\n",
    "    \n",
    "    'macro_html': (r'\\1', re.compile('\\{\\{\\{\\#\\!html (.+?)\\}\\}\\}')),\n",
    "    'macro_wiki': (r'\\2', re.compile('\\{\\{\\{\\#\\!wiki (.+?)\\n(.*)\\}\\}\\}')),\n",
    "    'macro_syntax': (r'\\2', re.compile('\\{\\{\\{\\#\\!syntax (.+?)\\n(.*)\\n\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_math': ('', re.compile('\\[math\\((.+?)\\)\\]', re.IGNORECASE)),\n",
    "    'macro_date': ('', re.compile('\\[date(time)?\\]', re.IGNORECASE)),\n",
    "    'macro_br': ('\\n', re.compile('\\[br\\]', re.IGNORECASE)),\n",
    "    'macro_include': ('', re.compile('\\[include(.+?)\\]', re.IGNORECASE)),\n",
    "    'macro_index': ('', re.compile('\\[목차\\]')),\n",
    "    'macro_index_': ('', re.compile('\\[tableofcontents\\]')),\n",
    "    'macro_footnote': ('', re.compile('\\[각주\\]')),\n",
    "    'macro_footnote_': ('', re.compile('\\[footnote\\]')),\n",
    "    'macro_pagecount': ('', re.compile('\\[pagecount(.+?)?\\]', re.IGNORECASE)),\n",
    "    'macro_age': ('', re.compile('\\[age\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_dday': ('', re.compile('\\[dday\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_tag': ('', re.compile('\\<(.+?)\\>')),\n",
    "\n",
    "    'attach_': (r'\\1', re.compile('\\[\\[파일:(.+?)\\|(.+?)\\]\\]')),\n",
    "    'attach': (r'\\1', re.compile('\\[\\[파일:(.+?)\\]\\]')),\n",
    "    \n",
    "    'paragraph_': (r'\\1', re.compile('\\[\\[#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'paragraph': (r'\\1', re.compile('\\[\\[#s-(.+?)\\]]')),\n",
    "    'link_paragraph_': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'link_paragraph': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\]\\]')),\n",
    "    'link': (r'\\1', re.compile('\\[\\[((?:(?!\\|).)+?)\\]\\]')),\n",
    "    'link_': (r'\\1', re.compile('\\[\\[(.+?)\\|(.+?)\\]\\]')),\n",
    "    \n",
    "    'list': (r'\\1', re.compile('\\|\\*\\|(.*)')),\n",
    "    'list_': (r'\\1', re.compile('\\|\\*(.*)')),\n",
    "    'list__': (r'\\1', re.compile('\\|[1Aa]\\.\\|(.*)')),\n",
    "    'list___': (r'\\1', re.compile('\\|[1Aa]\\.(.*)')),\n",
    "    'unordred_list': (r'\\1', re.compile('[ ]+\\*(.*)')),\n",
    "    'ordered_list': (r'\\1', re.compile('[ ]+[1AaIi]\\.(.*)')),\n",
    "    'quote': (r'\\1', re.compile('\\>+\\s?(.*)')),\n",
    "\n",
    "    'footnote': ('', re.compile('\\[\\*[A-Za-z]? (.+?)\\]')),    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str, verbose: bool = False) -> str:\n",
    "    def _parse(text: str, target: str, tag: re.Pattern) \\\n",
    "        -> Tuple[str, int]:\n",
    "        return tag.subn(target, text)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Parsing Regex {len(regex_tags.keys())} rules\\n\\t{text}')\n",
    "    \n",
    "    while True:\n",
    "        count = 0\n",
    "        for key, (target, tag) in regex_tags.items():\n",
    "            text, count = _parse(text, target, tag)\n",
    "            if count:\n",
    "                if verbose:\n",
    "                    print(f'Rule [{key}: {tag}]\\n\\t{text}')\n",
    "                break\n",
    "        if not count:\n",
    "            break\n",
    "            \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(text):\n",
    "    for row in regex_table.findall(text):\n",
    "        values = row.split('||')\n",
    "        yield values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get drama titles from channles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = [\"JTBC 금토 드라마(2014~2017)\", \"JTBC 금토 드라마(2017~2020)\", \"JTBC 드라마\", \"JTBC 수목 드라마\", \"JTBC 월화 드라마(2011~2014)\", \"JTBC 월화 드라마(2017~2020)\", \"JTBC 주말 드라마\", \"KBS 수목 드라마(2001~2005)\", \"KBS 수목 드라마(2006~2010)\", \"KBS 수목 드라마(2011~2015)\", \"KBS 수목 드라마(2016~2020)\", \"KBS 월화 드라마(2001~2005)\", \"KBS 월화 드라마(2006~2010)\", \"KBS 월화 드라마(2011~2015)\", \"KBS 월화 드라마(2016~2020)\", \"KBS 학교 시리즈\", \"MBC 수목 미니시리즈(2006~2010)\", \"MBC 수목 미니시리즈(2011~2015)\", \"MBC 수목 미니시리즈(2016~2020)\", \"MBC 아침 드라마(2011~2015)\", \"MBC 아침 드라마(2016~2020)\", \"MBC 예능 드라마\", \"MBC 월화 미니시리즈(2006~2010)\", \"MBC 월화 미니시리즈(2016~2020)\", \"MBC 월화특별기획(2011~2015)\", \"MBC 일일 드라마(2016~2020)\", \"MBC 일일 연속극(2011~2015)\", \"MBC 주말 드라마(2011~2015)\", \"MBC 주말 드라마(2016~2020)\", \"MBC 주말 특별기획(2011~2015)\", \"MBC 주말 특별기획(2016~2020)\", \"MBC 하이킥 시리즈\", \"MBN 수목 드라마\", \"OCN 로맨스 드라마\", \"OCN 수목 오리지널\", \"OCN 오리지널 드라마(2010~2016)\", \"OCN 월화 오리지널\", \"OCN 토일 오리지널(2017~2020)\", \"SBS 금토 드라마(2019~현재)\", \"SBS 드라마 스페셜(1992~1995)\", \"SBS 드라마 스페셜(1996~2000)\", \"SBS 드라마 스페셜(2001~2005)\", \"SBS 드라마 스페셜(2006~2010)\", \"SBS 드라마 스페셜(2011~2015)\", \"SBS 드라마 스페셜(2016~2020)\", \"SBS 아침 연속극(2016~2020)\", \"SBS 월화 드라마(1991~1995)\", \"SBS 월화 드라마(1996~2000)\", \"SBS 월화 드라마(2001~2005)\", \"SBS 월화 드라마(2006~2010)\", \"SBS 월화 드라마(2011~2015)\", \"SBS 월화 드라마(2016~2020)\", \"TV CHOSUN 토일드라마\", \"tvN 금요 드라마(2007~2015)\", \"tvN 금토 드라마\", \"tvN 로맨스가 필요해 시리즈\", \"tvN 불금 시리즈(2017~)\", \"tvN 월화 드라마(2011~2015)\", \"tvN 월화 드라마(2016~2020)\", \"tvN 토일 드라마(2017~2020)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interested:\n",
    "    document = context[inter]\n",
    "    matches = regex_document.findall(document['1']['text'])\n",
    "    \n",
    "    for match in matches:\n",
    "        name, *_ = match.split('|')\n",
    "        name, *_ = name.split('#')\n",
    "        titles.add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    '방송 기간': ['방송기간', '방송 기간'],\n",
    "    '방송 횟수': ['횟수', '방송 횟수'],\n",
    "    '장르': ['장르'],\n",
    "    '채널': ['채널', '방송사'],\n",
    "    '제작사': ['제작사', '제작자', '제작'],\n",
    "    '극본': ['극본', '대본'],\n",
    "    '출연자': ['출연자', '출연', '출연진'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)\n",
    "notexists = []\n",
    "notparser = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        if '(드라마)' not in title and f'{title}(드라마)' in context:\n",
    "            document = context[title]['0']['text']\n",
    "        else:\n",
    "            document = context[title]['0']['text']\n",
    "    except KeyError:\n",
    "        notexists.append(title)\n",
    "    \n",
    "    d = defaultdict(str)\n",
    "    for row in parse_table(parse(document)):\n",
    "        try:\n",
    "            key, value = filter(len, row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        key = next((ckey for ckey, cvalues in columns.items() if any(cvalue in key for cvalue in cvalues)), False)\n",
    "        if key:\n",
    "            key = key.strip()\n",
    "            d[key] = f'{d[key]} {value}'\n",
    "    \n",
    "    if not d:\n",
    "        notparser.append(title)\n",
    "    else:\n",
    "        data[title] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 pages are not parsable\n",
      "2 pages are not exists\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(notparser)} pages are not parsable')\n",
    "print(f'{len(notexists)} pages are not exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = list(columns.keys())\n",
    "table = np.empty((0, len(table_columns) + 1))\n",
    "\n",
    "for title, values in data.items():\n",
    "    table = np.vstack((table, np.array([\n",
    "        regex_bracket.sub('', title).replace(' ', '').strip(), *tuple(map(lambda c: values[c], table_columns))\n",
    "    ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.columns = ['제목', *table_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_date = re.compile('(.+?)년(.*)월(.*)일')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = []\n",
    "for index, date in enumerate(df['방송 기간']):\n",
    "    ds, *de = map(regex_date.findall, map(str.strip, date.split('~' if '~' in date else '-')))\n",
    "    ds, *_ = ds or ['unknown']\n",
    "    try:\n",
    "        date_start.append(pd.datetime(*tuple(map(int, ds))))\n",
    "    except (ValueError, TypeError):\n",
    "        date_start.append('unknown')\n",
    "    \n",
    "assert len(date_start) == np.size(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['방송 시작'] = pd.Series(date_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>방송 기간</th>\n",
       "      <th>방송 횟수</th>\n",
       "      <th>장르</th>\n",
       "      <th>채널</th>\n",
       "      <th>제작사</th>\n",
       "      <th>극본</th>\n",
       "      <th>출연자</th>\n",
       "      <th>방송 시작</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4월의키스</td>\n",
       "      <td>2004년 4월 21일 ~ 2004년 7월 8일</td>\n",
       "      <td>24부작</td>\n",
       "      <td>멜로, 드라마</td>\n",
       "      <td>한국방송공사</td>\n",
       "      <td>CAA</td>\n",
       "      <td>박범수</td>\n",
       "      <td>수애, 조한선, 이정진, 소이현 外</td>\n",
       "      <td>2004-04-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>으라차차와이키키2</td>\n",
       "      <td>2019년 3월 25일 ~ 2019년 5월 14일</td>\n",
       "      <td>16부작</td>\n",
       "      <td></td>\n",
       "      <td>JTBC</td>\n",
       "      <td>씨제스 프로덕션, 드라마하우스</td>\n",
       "      <td>김기호, 송지은, 송미소, 서동범</td>\n",
       "      <td>김선호, 이이경, 신현수(배우), 문가영, 안소희, 김예원(배우) 등</td>\n",
       "      <td>2019-03-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>타인은지옥이다</td>\n",
       "      <td>2019년 8월 31일 ~ 2019년  10월 6일</td>\n",
       "      <td>10부작</td>\n",
       "      <td>공포, 스릴러</td>\n",
       "      <td>OCN</td>\n",
       "      <td>스튜디오N , 영화사 우상</td>\n",
       "      <td>정이도</td>\n",
       "      <td>임시완, 이동욱, 이정은(1970) 外</td>\n",
       "      <td>2019-08-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마을-아치아라의비밀</td>\n",
       "      <td>2015년 10월 7일 ~ 2015년 12월 3일</td>\n",
       "      <td>16부작</td>\n",
       "      <td>서스펜스 스릴러, 공포, 판타지</td>\n",
       "      <td>SBS</td>\n",
       "      <td>래몽래인</td>\n",
       "      <td>도현정</td>\n",
       "      <td>문근영, 육성재, 신은경(배우) 外</td>\n",
       "      <td>2015-10-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>하이에나</td>\n",
       "      <td>ON AIR 2020년 2월 21일 ~</td>\n",
       "      <td>부작</td>\n",
       "      <td></td>\n",
       "      <td>SBS | 넷플릭스</td>\n",
       "      <td>SBS | 키이스트</td>\n",
       "      <td>김루리</td>\n",
       "      <td>김혜수, 주지훈 外</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           제목                            방송 기간    방송 횟수                    장르  \\\n",
       "0       4월의키스      2004년 4월 21일 ~ 2004년 7월 8일     24부작               멜로, 드라마    \n",
       "1   으라차차와이키키2     2019년 3월 25일 ~ 2019년 5월 14일     16부작                          \n",
       "2     타인은지옥이다    2019년 8월 31일 ~ 2019년  10월 6일     10부작               공포, 스릴러    \n",
       "3  마을-아치아라의비밀     2015년 10월 7일 ~ 2015년 12월 3일     16부작     서스펜스 스릴러, 공포, 판타지    \n",
       "4        하이에나          ON AIR 2020년 2월 21일 ~        부작                          \n",
       "\n",
       "              채널                  제작사                     극본  \\\n",
       "0        한국방송공사                  CAA                    박범수    \n",
       "1          JTBC     씨제스 프로덕션, 드라마하우스     김기호, 송지은, 송미소, 서동범    \n",
       "2           OCN       스튜디오N , 영화사 우상                    정이도    \n",
       "3           SBS                 래몽래인                    도현정    \n",
       "4    SBS | 넷플릭스           SBS | 키이스트                    김루리    \n",
       "\n",
       "                                         출연자                방송 시작  \n",
       "0                       수애, 조한선, 이정진, 소이현 外   2004-04-21 00:00:00  \n",
       "1    김선호, 이이경, 신현수(배우), 문가영, 안소희, 김예원(배우) 등   2019-03-25 00:00:00  \n",
       "2                     임시완, 이동욱, 이정은(1970) 外   2019-08-31 00:00:00  \n",
       "3                       문근영, 육성재, 신은경(배우) 外   2015-10-07 00:00:00  \n",
       "4                                김혜수, 주지훈 外               unknown  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../results/namuwiki.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
