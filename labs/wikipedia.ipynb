{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as etree\n",
    "from collections import defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read wikipedia dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.parse('../data/kowiki.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '{http://www.mediawiki.org/xml/export-0.10/}'\n",
    "keywords = ['title', 'id', 'revision/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in root[1:]:\n",
    "    data = {keyword: reduce(lambda node, key: node.find(f'{prefix}{key}'), [page, *keyword.split('/')]).text for keyword in keywords}\n",
    "    context[data['title']] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_document = re.compile('\\[\\[(.[^:]+?)\\]\\]')\n",
    "regex_attach = re.compile('\\[\\[파일:(.+?)\\]\\]')\n",
    "regex_comment = re.compile('\\[\\*(.+?)\\]')\n",
    "regex_table = re.compile('\\|(.+?)=(.+?)\\n')\n",
    "regex_link = re.compile('\\[\\[(.[^:\\[\\]]+?)\\|(.[^:\\[\\]]+?)\\]\\]')\n",
    "regex_del = re.compile('~~(.+?)~~')\n",
    "regex_tag = re.compile('\\<(.+?)\\>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get drama titles from channles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = [\"대한민국의 텔레비전 드라마 목록/ㄱ\", \"대한민국의 텔레비전 드라마 목록/ㄴ\", \"대한민국의 텔레비전 드라마 목록/ㄷ\", \"대한민국의 텔레비전 드라마 목록/ㄹ\", \"대한민국의 텔레비전 드라마 목록/ㅁ\", \"대한민국의 텔레비전 드라마 목록/ㅂ\", \"대한민국의 텔레비전 드라마 목록/ㅅ\", \"대한민국의 텔레비전 드라마 목록/ㅇ\", \"대한민국의 텔레비전 드라마 목록/ㅈ\", \"대한민국의 텔레비전 드라마 목록/ㅊ\", \"대한민국의 텔레비전 드라마 목록/ㅋ\", \"대한민국의 텔레비전 드라마 목록/ㅌ\", \"대한민국의 텔레비전 드라마 목록/ㅍ\", \"대한민국의 텔레비전 드라마 목록/ㅎ\", \"대한민국의 텔레비전 드라마 목록/알파벳\", \"대한민국의 텔레비전 드라마 목록/숫자\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interested:\n",
    "    document = context[inter]['revision/text']\n",
    "    matches = regex_documnet.findall(document)\n",
    "    \n",
    "    for match in matches:\n",
    "        name, *_ = match.split('|')\n",
    "        name, *_ = name.split('#')\n",
    "        if name != '대한민국의 텔레비전 드라마 목록':\n",
    "            titles.add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    '방송 기간': ['방송기간', '방송 기간'],\n",
    "    '방송 횟수': ['횟수', '방송 횟수'],\n",
    "    '장르': ['장르'],\n",
    "    '채널': ['채널', '방송사', '방송 채널', '방송채널'],\n",
    "    '제작사': ['제작사', '제작자', '제작'],\n",
    "    '극본': ['극본', '대본', '각본'],\n",
    "    '출연자': ['출연자', '출연', '출연진'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)\n",
    "notexists = []\n",
    "notparser = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        document = context[title]['revision/text']                  \n",
    "    except KeyError:\n",
    "        notexists.append(title)\n",
    "        \n",
    "    matches = regex_table.findall(document)\n",
    "    \n",
    "    d = {key: '' for key in columns}\n",
    "    \n",
    "    for key_value in matches:\n",
    "        key, value = map(str.strip, key_value)\n",
    "        key = next((ckey for ckey, cvalues in columns.items() if any(cvalue in key for cvalue in cvalues)), False)\n",
    "        if key:\n",
    "            d[key] = value\n",
    "    \n",
    "    if not d:\n",
    "        notparser.append(title)\n",
    "    else:\n",
    "        data[title] = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = list(columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.empty((0, len(table_columns) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, values in data.items():\n",
    "    d = [regex_tag.sub('', regex_comment.sub('', regex_del.sub(r'\\1', regex_documnet.sub(r'\\1', regex_link.sub(r'\\1', regex_attach.sub('attach', values[column])))))).strip() \n",
    "         for column in table_columns]\n",
    "    table = np.vstack((table, np.array([title, *d])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.columns = ['title', *table_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../results/namuwiki.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
