{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import re\n",
    "import xml.etree.ElementTree as etree\n",
    "from collections import defaultdict, OrderedDict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read wikipedia dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.parse('../data/kowiki.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '{http://www.mediawiki.org/xml/export-0.10/}'\n",
    "keywords = ['title', 'id', 'revision/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(node, key):\n",
    "    return node.find(f'{prefix}{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in root[1:]:\n",
    "    data = {keyword: reduce(parse_xml, [page, *keyword.split('/')]).text for keyword in keywords}\n",
    "    context[data['title']] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_document = re.compile('\\[\\[(.[^:]+?)\\]\\]')\n",
    "regex_table = re.compile('\\{\\{((?:.|\\n)*)\\}\\}')\n",
    "regex_table_column = re.compile('\\|(.+?)\\=([^\\|]*)')\n",
    "regex_bracket = re.compile('\\((.+?)\\)')\n",
    "regex_redirect = re.compile('#넘겨주기 \\[\\[(.+?)\\]\\]')\n",
    "\n",
    "regex_tags = OrderedDict({\n",
    "    'horizontal_line': ('', re.compile('\\-{4,9}')),\n",
    "    'comment': ('', re.compile('##\\s?(.*)')),\n",
    "    'indent': (r'\\1', re.compile('\\:{1,}(.+?)$')),\n",
    "    \n",
    "    'header': (r'\\1', re.compile('\\={2,6}\\#?(.+?)\\#?\\={2,6}')),\n",
    "    'bold': (r'\\1', re.compile(\"\\'\\'\\'(.+?)\\'\\'\\'\")),\n",
    "    'italic': (r'\\1', re.compile(\"\\'\\'(.+?)\\'\\'\")),\n",
    "    'strike1': (r'\\1', re.compile('~~(.+?)~~')),\n",
    "    'strike2': (r'\\1', re.compile('--(.+?)--')),\n",
    "    'underline': (r'\\1', re.compile('__(.+?)__')),\n",
    "    'upper': (r'\\1', re.compile('\\^\\^(.+?)\\^\\^')),\n",
    "    'under': (r'\\1', re.compile(',,(.+?),,')),\n",
    "    \n",
    "    'bigger': (r'\\1', re.compile('\\{\\{\\{\\+[1-5] (.+?)\\}\\}\\}')),\n",
    "    'smaller': (r'\\1', re.compile('\\{\\{\\{\\-[1-5] (.+?)\\}\\}\\}')),\n",
    "    'color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}')),\n",
    "    'without_markup': (r'\\1', re.compile('\\{\\{\\{(.*)\\}\\}\\}')),\n",
    "    \n",
    "    'macro_html': (r'\\1', re.compile('\\{\\{\\{\\#\\!html (.+?)\\}\\}\\}')),\n",
    "    'macro_wiki': (r'\\2', re.compile('\\{\\{\\{\\#\\!wiki (.+?)\\n(.*)\\}\\}\\}')),\n",
    "    'macro_syntax': (r'\\2', re.compile('\\{\\{\\{\\#\\!syntax (.+?)\\n(.*)\\n\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_color': (r'\\2', re.compile('\\{\\{\\{\\#(.+?) (.+?)\\}\\}\\}', re.IGNORECASE)),\n",
    "    'macro_math': ('', re.compile('\\[math\\((.+?)\\)\\]', re.IGNORECASE)),\n",
    "    'macro_date': ('', re.compile('\\[date(time)?\\]', re.IGNORECASE)),\n",
    "    'macro_br': ('\\n', re.compile('\\<br \\/\\>', re.IGNORECASE)),\n",
    "    'macro_include': ('', re.compile('\\[include(.+?)\\]', re.IGNORECASE)),\n",
    "    'macro_index': ('', re.compile('\\[목차\\]')),\n",
    "    'macro_index_': ('', re.compile('\\[tableofcontents\\]')),\n",
    "    'macro_footnote': ('', re.compile('\\[각주\\]')),\n",
    "    'macro_footnote_': ('', re.compile('\\[footnote\\]')),\n",
    "    'macro_pagecount': ('', re.compile('\\[pagecount(.+?)?\\]', re.IGNORECASE)),\n",
    "    'macro_age': ('', re.compile('\\[age\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_dday': ('', re.compile('\\[dday\\(\\)\\]', re.IGNORECASE)),\n",
    "    'macro_tag': ('', re.compile('\\<(.+?)\\>')),\n",
    "\n",
    "    'attach_': (r'\\1', re.compile('\\[\\[파일:(.+?)\\|(.+?)\\]\\]')),\n",
    "    'attach': (r'\\1', re.compile('\\[\\[파일:(.+?)\\]\\]')),\n",
    "    \n",
    "    'paragraph_': (r'\\1', re.compile('\\[\\[#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'paragraph': (r'\\1', re.compile('\\[\\[#s-(.+?)\\]]')),\n",
    "    'link_paragraph_': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\|(.+?)\\]\\]')),\n",
    "    'link_paragraph': (r'\\1', re.compile('\\[\\[(.+?)#s-(.+?)\\]\\]')),\n",
    "    'link': (r'\\1', re.compile('\\[\\[((?:(?!\\|).)+?)\\]\\]')),\n",
    "    'link_': (r'\\1', re.compile('\\[\\[(.+?)\\|(.+?)\\]\\]')),\n",
    "    'link__': (r'\\1', re.compile('\\{\\{(.+?)\\|(.+?)\\}\\}')),\n",
    "    \n",
    "    'unordered_list': (r'\\1', re.compile('\\*{1,}:?(.*)')),\n",
    "    'ordered_list': (r'\\1', re.compile('\\#{1,}:?(.*)')),\n",
    "    \n",
    "    \n",
    "    'list_': (r'\\1', re.compile('\\|\\*(.*)')),\n",
    "    'list__': (r'\\1', re.compile('\\|[1Aa]\\.\\|(.*)')),\n",
    "    'list___': (r'\\1', re.compile('\\|[1Aa]\\.(.*)')),\n",
    "    'unordred_list': (r'\\1', re.compile('[ ]+\\*(.*)')),\n",
    "    'quote': (r'\\1', re.compile('\\>+\\s?(.*)')),\n",
    "\n",
    "    'footnote': ('', re.compile('\\[\\*[A-Za-z]? (.+?)\\]')),    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str, verbose: bool = False) -> str:\n",
    "    def _parse(text: str, target: str, tag: re.Pattern) \\\n",
    "        -> Tuple[str, int]:\n",
    "        return tag.subn(target, text)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Parsing Regex {len(regex_tags.keys())} rules\\n\\t{text}')\n",
    "    \n",
    "    while True:\n",
    "        count = 0\n",
    "        for key, (target, tag) in regex_tags.items():\n",
    "            text, count = _parse(text, target, tag)\n",
    "            if count:\n",
    "                if verbose:\n",
    "                    print(f'Rule [{key}: {tag}]\\n\\t{text}')\n",
    "                break\n",
    "        if not count:\n",
    "            break\n",
    "            \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(text):\n",
    "    for row in regex_table.findall(document):\n",
    "        yield regex_table_column.findall(parse(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get drama titles from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = [\"대한민국의 텔레비전 드라마 목록/ㄱ\", \"대한민국의 텔레비전 드라마 목록/ㄴ\", \"대한민국의 텔레비전 드라마 목록/ㄷ\", \"대한민국의 텔레비전 드라마 목록/ㄹ\", \"대한민국의 텔레비전 드라마 목록/ㅁ\", \"대한민국의 텔레비전 드라마 목록/ㅂ\", \"대한민국의 텔레비전 드라마 목록/ㅅ\", \"대한민국의 텔레비전 드라마 목록/ㅇ\", \"대한민국의 텔레비전 드라마 목록/ㅈ\", \"대한민국의 텔레비전 드라마 목록/ㅊ\", \"대한민국의 텔레비전 드라마 목록/ㅋ\", \"대한민국의 텔레비전 드라마 목록/ㅌ\", \"대한민국의 텔레비전 드라마 목록/ㅍ\", \"대한민국의 텔레비전 드라마 목록/ㅎ\", \"대한민국의 텔레비전 드라마 목록/알파벳\", \"대한민국의 텔레비전 드라마 목록/숫자\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interested:\n",
    "    document = context[inter]['revision/text']\n",
    "    matches = regex_document.findall(document)\n",
    "    \n",
    "    for match in matches:\n",
    "        name, *_ = match.split('|')\n",
    "        name, *_ = name.split('#')\n",
    "        if name != '대한민국의 텔레비전 드라마 목록':\n",
    "            titles.add(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    '방송 기간': ['방송기간', '방송 기간'],\n",
    "    '방송 횟수': ['횟수', '방송 횟수'],\n",
    "    '장르': ['장르'],\n",
    "    '채널': ['채널', '방송사', '방송 채널', '방송채널'],\n",
    "    '제작사': ['제작사', '제작자', '제작'],\n",
    "    '극본': ['극본', '대본', '각본'],\n",
    "    '출연자': ['출연자', '출연', '출연진'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)\n",
    "notexists = []\n",
    "notparser = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        if '(드라마)' not in title and f'{title} (드라마)' in context:\n",
    "            document, redirect = context[f'{title} (드라마)']['revision/text'], True\n",
    "        else:\n",
    "            document, redirect = context[title]['revision/text'], True\n",
    "        while redirect:\n",
    "            document, redirect = regex_redirect.subn(r'\\1', document)\n",
    "            if redirect:\n",
    "                document = context[document]['revision/text']\n",
    "    except KeyError:\n",
    "        notexists.append(title)\n",
    "    \n",
    "    d = defaultdict(str)    \n",
    "    for table in parse_table(document):\n",
    "        for row in table:\n",
    "            try:\n",
    "                key, value = map(str.strip, filter(len, row))\n",
    "            except ValueError:\n",
    "                continue\n",
    "            key = next((ckey for ckey, cvalues in columns.items() if any(cvalue in key for cvalue in cvalues)), False)\n",
    "            if key:\n",
    "                key = key.strip()\n",
    "                d[key] = f'{d[key]} {value}'\n",
    "            \n",
    "    if not d:\n",
    "        notparser.append(title)\n",
    "    else:\n",
    "        data[title] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 pages are not parsable\n",
      "16 pages are not exists\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(notparser)} pages are not parsable')\n",
    "print(f'{len(notexists)} pages are not exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = list(columns.keys())\n",
    "table = np.empty((0, len(table_columns) + 1))\n",
    "\n",
    "for title, values in data.items():\n",
    "    table = np.vstack((table, np.array([\n",
    "        regex_bracket.sub('', title).replace(' ', '').strip(), *tuple(map(lambda c: values[c], table_columns))\n",
    "    ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table)\n",
    "df.columns = ['제목', *table_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_date = re.compile('(.+?)년(.*)월(.*)일')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = []\n",
    "for index, date in enumerate(df['방송 기간']):\n",
    "    ds, *de = map(regex_date.findall, map(str.strip, date.split('~' if '~' in date else '-')))\n",
    "    ds, *_ = ds or ['unknown']\n",
    "    try:\n",
    "        date_start.append(pd.datetime(*tuple(map(int, ds))))\n",
    "    except (ValueError, TypeError):\n",
    "        date_start.append('unknown')\n",
    "    \n",
    "assert len(date_start) == np.size(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['방송 시작'] = pd.Series(date_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1760, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>방송 기간</th>\n",
       "      <th>방송 횟수</th>\n",
       "      <th>장르</th>\n",
       "      <th>채널</th>\n",
       "      <th>제작사</th>\n",
       "      <th>극본</th>\n",
       "      <th>출연자</th>\n",
       "      <th>방송 시작</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>해피시스터즈</td>\n",
       "      <td>2017년 12월 4일 ~ 2018년 5월 25일</td>\n",
       "      <td>120부작</td>\n",
       "      <td>드라마</td>\n",
       "      <td>SBS TV</td>\n",
       "      <td>SBS 플러스 김용진</td>\n",
       "      <td>한영미</td>\n",
       "      <td>심이영, 한영 (가수), 오대규,강서준, 이시강, 반소영 외</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미쓰아줌마</td>\n",
       "      <td>2011년 5월 30일 ~ 2011년 10월 21일</td>\n",
       "      <td>103부작</td>\n",
       "      <td>텔레비전 드라마, 멜로</td>\n",
       "      <td>SBS</td>\n",
       "      <td>윤하림 화앤담픽쳐스</td>\n",
       "      <td>송정림</td>\n",
       "      <td>오현경, 권오중, 정시아, 김정민 (가수) 외</td>\n",
       "      <td>2011-05-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>배가본드</td>\n",
       "      <td>2019년 9월 20일  ~ 2019년 11월 23일</td>\n",
       "      <td>16부작</td>\n",
       "      <td>범죄, 첩보, 액션,  재난</td>\n",
       "      <td>SBS TV, 넷플릭스</td>\n",
       "      <td>셀트리온 엔터테인먼트 박재삼</td>\n",
       "      <td>장영철 (작가), 정경순 (작가)</td>\n",
       "      <td>이승기, 배수지, 신성록 외</td>\n",
       "      <td>2019-09-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>전설의고향-1998년</td>\n",
       "      <td>1998년 7월 6일 ~ 1998년 8월 11일</td>\n",
       "      <td>12부작</td>\n",
       "      <td>텔레비전 드라마</td>\n",
       "      <td>KBS 2TV</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1998-07-06 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>결혼합시다</td>\n",
       "      <td>2002년 7월 15일 ~ 2002년 12월 27일</td>\n",
       "      <td>117부작</td>\n",
       "      <td>드라마 · 연속극</td>\n",
       "      <td>KBS 2TV</td>\n",
       "      <td>이진석 (연출가) 제이에스픽쳐스</td>\n",
       "      <td>이유선, 이홍주</td>\n",
       "      <td>김창숙 (1949년), 주현, 이아현, 임지은 외</td>\n",
       "      <td>2002-07-15 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            제목                           방송 기간   방송 횟수                장르  \\\n",
       "0       해피시스터즈     2017년 12월 4일 ~ 2018년 5월 25일   120부작               드라마   \n",
       "1        미쓰아줌마    2011년 5월 30일 ~ 2011년 10월 21일   103부작      텔레비전 드라마, 멜로   \n",
       "2         배가본드   2019년 9월 20일  ~ 2019년 11월 23일    16부작   범죄, 첩보, 액션,  재난   \n",
       "3  전설의고향-1998년      1998년 7월 6일 ~ 1998년 8월 11일    12부작          텔레비전 드라마   \n",
       "4        결혼합시다    2002년 7월 15일 ~ 2002년 12월 27일   117부작         드라마 · 연속극   \n",
       "\n",
       "              채널                 제작사                   극본  \\\n",
       "0         SBS TV         SBS 플러스 김용진                  한영미   \n",
       "1            SBS          윤하림 화앤담픽쳐스                 송정림    \n",
       "2   SBS TV, 넷플릭스     셀트리온 엔터테인먼트 박재삼   장영철 (작가), 정경순 (작가)   \n",
       "3        KBS 2TV                                            \n",
       "4        KBS 2TV   이진석 (연출가) 제이에스픽쳐스             이유선, 이홍주   \n",
       "\n",
       "                                  출연자                방송 시작  \n",
       "0   심이영, 한영 (가수), 오대규,강서준, 이시강, 반소영 외  2017-12-04 00:00:00  \n",
       "1           오현경, 권오중, 정시아, 김정민 (가수) 외  2011-05-30 00:00:00  \n",
       "2                     이승기, 배수지, 신성록 외  2019-09-20 00:00:00  \n",
       "3                                      1998-07-06 00:00:00  \n",
       "4         김창숙 (1949년), 주현, 이아현, 임지은 외  2002-07-15 00:00:00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../results/wikipedia.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
